\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{hyperref} % For hyperlinks in the PDF
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Machine Learning for Pinnacle Matchmaking in \textit{Destiny 2}\\
    % This footnote is usually used for funding; we acknowledge course staff 
    % here instead. They granted us w/ knowledge, I suppose?
    \thanks{This project was done for CS229: Machine Learning.
        The code is available on GitHub at
        \href{https://github.com/garrickf/d2-ml}{garrickf/d2-ml}.
        Thanks to Prof. Moses Charikar, Prof. Chris Ré, and the rest of the teaching team for their
        feedback on the project and a great class!}
}

\author{\IEEEauthorblockN{Garrick Fernandez}
    \IEEEauthorblockA{\textit{Department of Computer Science} \\
        \textit{Stanford University}\\
        Stanford, CA\\
        garrick@cs.stanford.edu}
}

\maketitle

\begin{abstract}
    Video games often contain online components that allow players across the world
    to interact and play with one another. The systems which perform the matching
    of players into teams are often collectively referred to as ``matchmaking.'' We
    focus on analyzing matchmaking in the video game \textit{Destiny 2}, an
    online first-person shooter developed by Bungie. In this paper, we develop and
    apply machine learning techniques to Destiny 2 game data exposed by the
    Bungie.net Platform API, with the goal of predicting the ``success'' of the
    matching of a group of player, as measured by end of game standing and time to
    activity completion. The main contributions of this paper are (1) a structured
    data pipeline for retrieving, processing and aggregating data scraped from the
    Platform API, (2) data analysis and application of machine learning for
    supervised and unsupervised tasks, and (3) explorations of and proposals for
    future work in feature engineering.
\end{abstract}

\begin{IEEEkeywords}
    Category: Finance and Commerce, video games, matchmaking, regression, data
    collection, API
\end{IEEEkeywords}

\section{Introduction and Problem Motivation}

In the realm of online gaming, \textit{Destiny 2} is unique in that it
facilitates player interaction in many ways. Players can organically encounter
each other online while exploring the game's many worlds, as well as prompt to
get matched with other players in order to participate in cooperative and
competitive activities. This latter process, a more explicit form of
matchmaking, depends on the fact that there are other players currently online
who are looking to play the same activity. However, there are some activities
that have matchmaking disabled, due to the difficulty, coordination, and
prerequisites required for the activity (these activities are referred to as
``pinnacle'' or ``aspirational'' activities—the things you do to demonstrate
mastery over the game).

This design choice has created an ecosystem around finding people to play with,
and there are already several established networks that exist for finding
teammates, such as LFG (``looking for group") websites, and clans, organized
groups of players that regularly play together. Bungie themselves have an
in-game matchmaking solution, called Guided Games, which attempts to pair solo
players (Seekers) and organized teams (Guides). Unfortunately, Guided Games has
been in beta since the game's original release in 2017 \cite{guided-games},
and it suffers from low concurrent player populations and, by extension, long
queue times. The advantage of clan membership (and, to some extent, using LFG
apps) are that players can schedule activities in advance, but these routes can
be intimidating to new or introverted players. One potential approach that
could improve the experience of looking for a team would be to use a system to
recommend other players they could play an activity with right now, or in the
near future: a ``team-activity-time" recommendation. Instead of putting the
onus on a player to find a group, the system can take advantage of the fact
that many people are in similar situations, wanting to play the same
activity—and proactively match them.

As a step towards that goal, we employ a number of machine learning techniques
on data publicly accessible via the Bungie.net Platform API
\cite{api}, with the goal of evaluating the success or fitness of a
matched group of players. This system could be employed in a matchmaking
pipeline to make recommendations on which players could play an activity
together.

More formally, we define our task as a supervised learning task, where the
examples are historical games whose information we can query from the API, and
the labels are measures of ``success'' reported by the game—for example, the
time it takes to complete an activity, or the team's standing, victory or
defeat, at the end of a game.

The paper is structured as follows: In section \ref{DC}, we
outline a process for scraping data from the \textit{Destiny 2} API. In
section \ref{M}, we outline the methods we tried for learning on
our task. In section \ref{RI}, we evaluate the results of our
exploration In section \ref{RW}, we situate our work and results
in the existing literature In section \ref{CFW}, we summarize our
results and discuss avenues for future work.

\section{Data Collection}\label{DC}

Collecting data was a significant component of the project due to the nature of
its source. Traditional datasets with well-formed features are not publicly
available for \textit{Destiny 2}; however, some data is exposed via the
Bungie.net Platform API, opening the door for scraping together a dataset. The
API contains upwards of 100 endpoints that allow both first-party and
third-party apps to access and manipulate various in-game and player data.

Of these many endpoints, only a subset provide any useful information for our
learning task. For example, the \texttt{Destiny2.GetPostGameCarnageReport} endpoint returns a
summary of information related with a given \texttt{activityId}, internally
referred to as a post-game carnage report (PGCR). The \texttt{activityId} is
an unsigned 64-bit integer, and it is assigned to activities in ascending
order. See Fig.~\ref{response} for an example PGCR response.

\begin{figure}[htbp]
    \begin{verbatim}
{
    "Response": {
        "period": "2021-05-07T10:06:12Z",
        "startingPhaseIndex": 0,
        "activityDetails": {
            "referenceId": 1575864965,
            "directorActivityHash": ...,
            "instanceId": "8400554258",
            "mode": 63,
            "modes": [
                64,
                63
            ],
            "isPrivate": false,
            "membershipType": 3
        },
        ...
    }
}
    \end{verbatim}
    \caption{Truncated JSON PGCR response (full length is 2844 lines) for
        \texttt{activityId = 8400554258}. This is a game of Gambit (a competitive player vs.
        player mode, with additional non-player combatants (the ``environment''), often called PvPvE.
        There are additional fields for player statistics and
        game metadata.}
    \label{response}
\end{figure}

Assuming we rate-limit our requests to 25 per-second (the limit imposed by the
API), querying activity information for every \texttt{activityId} from
September 2017 to the present would take upwards of 10 years! To make things
feasible, we limit our range to a period of 100K/1M activities performed
starting at an arbitrary \texttt{activityId} (we picked one for a game played
around May). We implemented a threadpool to
parallelize outgoing requests, rate-limiting to avoid throttling; this sped up
data collection by up to fourteen fold.

An additional layer of complication in the data collection is the presence of
hashes in the response rather than localized English strings (see See
Fig.~\ref{response}, \texttt{directorActivityHash}). The API is
internationalized, and so the API responses are decoupled from any language,
and an additional hydration step is needed to transform hashes into localized
English strings. In particular, a manifest (a file containing metadata for a
group of accompanying files—in our case, all the data we can query from the
platform API) can be downloaded as a compressed SQLite database. The tables
therein map hashes to localized strings, representing static definitions of
objects found within \textit{Destiny}.

We wrote an additional script script to download the manifest and process it
into an index used in the data collection routine.

Once collected and processed, our data had

\section{Methods}\label{M}
There are multiple factors of ``success'' in a single \textit{Destiny 2}
game or match. If the game mode does not contain opposing teams (player vs.
environment, or PvE), the activity completion time can be taken as a metric of
team cohesion and success. The longer the time to completion, the worse the
team did. In competitive game modes (PvP or PvPvE), there are separate
competing teams, and the standing, or end-of-game result (victory or defeat)
can be taken as a metric of team success.

In order to learn and predict completion time, we consider several methods. One
method is linear regression, whose cost function is given by:

\begin{equation}
    J(\theta) = \frac{1}{2} \sum_{i = 1}^n
    (h_\theta (x^{(i)}) - y^{(i)})^2
\end{equation}

where $h_\theta(x) = \sum_{i=0}^d \theta_i x_i = \theta^\top
    x$ (we use the convention of letting
$x_0 = 1$, the intercept). This function is convex. We can derive
this cost function from a probabilistic/MLE perspective. The vectorized update
rule for batch gradient descent is

\begin{equation}
    \theta := \theta + \alpha \sum_{i=1}^n
    (y^{(i)} -
    h_\theta (x^{(i)}))x^{(i)}\label{lms-update}
\end{equation}

Notice we don't normalize over the number of examples (as is convention with
neural networks). Also note that the negative sign typical in gradient descent
(we move against the direction of the gradient to minimize the cost function)
has been pushed inside the sum in \eqref{lms-update}.

As there are a lot of features, and some of them may be collinear (for example,
the number of kills versus the number of combatants defeated, i.e., kills and
assists), regularization may result in better, simpler models and less
overfitting to the training data. We consider ridge regression and lasso
regression, whose cost functions are least squares with L2 and L1
regularization, respectively. The cost function for Ridge regression is:

\begin{equation}
    J(\theta) = \frac{1}{2} \sum_{i = 1}^n
    (h_\theta (x^{(i)}) - y^{(i)})^2 + \lambda
    \|\theta\|_2
\end{equation}

Where $\lambda$ is the regularization strength. The cost function
for Lasso regression is:

\begin{equation}
    J(\theta) = \frac{1}{2} \sum_{i = 1}^n
    (h_\theta (x^{(i)}) - y^{(i)})^2 + \gamma
    \|\theta\|_1
\end{equation}

Where $\gamma$ is the regularization strength. By taking a
Bayesian interpretation of regularization, we can view ridge and lasso
regression as having a Gaussian and Laplace prior over the parameters
$\theta$, respectively. Both priors encourage the parameter values
to be closer to their mean (i.e., zero), resulting in a shrinkage effect. In
particular, lasso regression is known to result in sparse parameters, where
most parameter values are zero, and only some are non-zero. This could be
useful for identifying which features are the most useful for our learning
task.

\subsection{Tools}
We used an external library, scikit-learn \cite{sklearn}, to perform
the methods described above.

\section{Experiments, Results and Interpretation}\label{RI}

\section{Related Work}\label{RW}

\section{Conclusion and Future Work}\label{CFW}

% \begin{table}[htbp]
%     \caption{Table Type Styles}
%     \begin{center}
%         \begin{tabular}{|c|c|c|c|}
%             \hline
%             \textbf{Table} & \multicolumn{3}{|c|}{\textbf{Table Column Head}}                                                         \\
%             \cline{2-4}
%             \textbf{Head}  & \textbf{\textit{Table column subhead}}           & \textbf{\textit{Subhead}} & \textbf{\textit{Subhead}} \\
%             \hline
%             copy           & More table copy$^{\mathrm{a}}$                   &                           &                           \\
%             \hline
%             \multicolumn{4}{l}{$^{\mathrm{a}}$Sample of a Table footnote.}
%         \end{tabular}
%         \label{tab1}
%     \end{center}
% \end{table}

\begin{thebibliography}{00}
    % Intro
    \bibitem{guided-games} ``Guided games: bungie help,''
    \url{https://help.bungie.net/hc/en-us/articles/360049198951-Guided-Games} (Accessed June 2021).

    \bibitem{api} ``Bungie.net api,'' \url{https://bungie-net.github.io/multi/index.html} (Accessed June 2021).

    % Methods
    \bibitem{sklearn}
    "Scikit-learn: machine learning in python," \url{https://scikit-learn.org/stable/} (accessed May 2021).
\end{thebibliography}

\end{document}
